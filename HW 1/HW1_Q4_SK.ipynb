{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1\n",
        "\n",
        "Veera Anand, Aarav Dewangan, Samuel Martinez Koss, and John Melel.\n",
        "\n",
        "Notes:\n",
        "\n",
        "- Questions 01, 02, 03, 04 from ``0001-01-02-02_performance-metrics_homework.html``\n",
        "\n",
        "- Bonus Question from ``0001-01-01-02_bias_vs_variance_homework.html``"
      ],
      "metadata": {
        "id": "t-yR8CmTVO-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "ptdPvWdRYhYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEM3V2_dYio0",
        "outputId": "e270c3fe-2c14-4633-9188-1a0c48d76d9d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir_sam = '/content/drive/MyDrive/[96] MS-ADS/ADSP 31018 -- Machine Learning II/adsp-31018-machine-learning-2/data'\n",
        "\n",
        "base_dir = base_dir_sam\n",
        "os.chdir(base_dir)\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhLKPBOWY6TS",
        "outputId": "e0fd82f2-29e3-4d8d-dcd3-0aee0f0213b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1IrvmCPGR8kslT0s_vcGNpM2PQGQBbV_L/adsp-31018-machine-learning-2/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.options.display.float_format = '{:,.4f}'.format"
      ],
      "metadata": {
        "id": "bAwT8AebY_CB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 01\n",
        "\n",
        "Datasets ``binomial-classification-v1.csv`` and ``binomial-classification-v2.csv`` contain actuals and predictions values from a binomial response variable.\n",
        "\n",
        "1. Print one record containing a true/positive, true/negative, false/positive, false/negative\n",
        "\n",
        "2. Manually compute accuracy, precision, recall, f1_Score\n",
        "\n",
        "3. Compute the metrics in item 2 using sklearn and tensorflow, and torch\n",
        "\n",
        "4. Show the values matching across all three computing approaches"
      ],
      "metadata": {
        "id": "PtcNAAQzVtYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binom1 = pd.read_csv('binomial-classification-v1.csv')\n",
        "binom2 = pd.read_csv('binomial-classification-v2.csv')"
      ],
      "metadata": {
        "id": "epNDXsRVYgln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binom01 = pd.concat([binom1, binom2], ignore_index=True)"
      ],
      "metadata": {
        "id": "fSDRpLDaili7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1."
      ],
      "metadata": {
        "id": "QqToj2JHmIxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neg = binom01.loc[binom01['predicted'] == 0]\n",
        "pos = binom01.loc[binom01['predicted'] == 1]\n",
        "\n",
        "TP = pos.loc[pos['actual'] == 1]\n",
        "TN = neg.loc[neg['actual'] == 0]\n",
        "FP = pos.loc[pos['actual'] == 0]\n",
        "FN = neg.loc[neg['actual'] == 1]\n",
        "\n",
        "print(\"Example Record Containing a True/Positive:\\n\", TP.sample(), \"\\n\")\n",
        "print(\"Example Record Containing a True/Negative:\\n\", TN.sample(), \"\\n\")\n",
        "print(\"Example Record Containing a False/Positive:\\n\", FP.sample(), \"\\n\")\n",
        "print(\"Example Record Containing a False/Negative:\\n\", FN.sample())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2d5rTAUiyoO",
        "outputId": "7bd1c5f6-1e00-4948-df32-e7f1e765c35e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Record Containing a True/Positive:\n",
            "        Unnamed: 0  actual  predicted\n",
            "15472        5473       1          1 \n",
            "\n",
            "Example Record Containing a True/Negative:\n",
            "        Unnamed: 0  actual  predicted\n",
            "13076        3077       0          0 \n",
            "\n",
            "Example Record Containing a False/Positive:\n",
            "       Unnamed: 0  actual  predicted\n",
            "8335        8335       0          1 \n",
            "\n",
            "Example Record Containing a False/Negative:\n",
            "       Unnamed: 0  actual  predicted\n",
            "7077        7077       1          0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2."
      ],
      "metadata": {
        "id": "VH4m7igKmKfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3."
      ],
      "metadata": {
        "id": "NN-1JIHpmLe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4."
      ],
      "metadata": {
        "id": "es2UJOI-mM_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 02\n",
        "\n",
        "Dataset ``binomial-classification-v3.csv`` contain actuals and probability prediction values from a binomial response variable.\n",
        "\n",
        "1. Manually compute the log loss\n",
        "\n",
        "2. Compute the log loss using sklearn, tensorflow, and torch\n",
        "\n",
        "3. Show the values matching across all three computing approaches"
      ],
      "metadata": {
        "id": "TVqQwp47XxGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binom3 = pd.read_csv('binomial-classification-v3.csv')"
      ],
      "metadata": {
        "id": "FEKsjMqRYgCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 03\n",
        "\n",
        "Dataset ``regression-v1.csv`` contains actuals and predictions from a normally distributed response variable with a varying mean but constant variance.\n",
        "\n",
        "1. Manually compute mean absolute error, mean squared error, r2, explained variance score, and mean absolute percentage error\n",
        "\n",
        "2. Compute the metrics in item 2 using sklearn and tensorflow, and torch\n",
        "\n",
        "3. Document that the values match across all three computing approaches"
      ],
      "metadata": {
        "id": "Yc5xSDDUXxZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg1 = pd.read_csv('regression-v1.csv')"
      ],
      "metadata": {
        "id": "O0T31bOhYflQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "1833bf40-d6ce-4d12-b2bf-bea4967e927f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e4d049ece065>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'regression-v1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 04\n",
        "\n",
        "Dataset ``multinomial-classification-v1.csv`` contains actuals and predictions for a multinomial response variable. Manually compute the performance and check that it matches in sklearn, tensorflow, and torch.\n",
        "\n",
        "Helper functions and other code modified from ``0001-01-02-01_performance-metrics_lecture.html``"
      ],
      "metadata": {
        "id": "ka-FAXuUXxop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multinom1 = pd.read_csv('multinomial-classification-v1.csv')"
      ],
      "metadata": {
        "id": "d4YL9-rfYfOG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "aCLp8kvOwov-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actuals = multinom1[['y1', 'y2', 'y3']].to_numpy()\n",
        "predictions = multinom1[['p1', 'p2', 'p3']].to_numpy()\n",
        "num_classes = predictions.shape[1]\n",
        "\n",
        "actuals_pt = torch.tensor(actuals).clone().detach()\n",
        "predictions_pt = torch.tensor(predictions).clone().detach()\n",
        "\n",
        "actuals_tf = tf.convert_to_tensor(actuals, dtype=tf.float32)\n",
        "predictions_tf = tf.convert_to_tensor(predictions, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "gejurxrYqmLz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy By Category"
      ],
      "metadata": {
        "id": "8JSVhX29t8tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected Manual Accuracy per Class Calculation\n",
        "def accuracy_per_class(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes accuracy per class (class-wise accuracy) based on thresholded predictions.\n",
        "    \"\"\"\n",
        "    return np.array([np.mean(y_true[:, i] == np.round(y_pred[:, i])) for i in range(y_true.shape[1])])"
      ],
      "metadata": {
        "id": "JwfyoT9cvZkY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_per_class = accuracy_per_class(actuals, predictions)\n",
        "print(f\"Manually computed Accuracies by Category: {acc_per_class.tolist()}\")\n",
        "\n",
        "accuracies_sklearn = [accuracy_score(actuals[:, i], predictions[:, i].round()) for i in range(num_classes)]\n",
        "print(f\"Scikit-learn Accuracies by Category     : {accuracies_sklearn}\")\n",
        "\n",
        "accuracies_pt = []\n",
        "for i in range(num_classes):\n",
        "    # predicted_i >= 0.5 => predicted as \"1\" for class i\n",
        "    pred_binary = (predictions_pt[:, i] >= 0.5).float()\n",
        "    # actuals[:, i] is 1 or 0 if truly one-hot\n",
        "    acc_i = (pred_binary == actuals_pt[:, i]).float().mean()\n",
        "    accuracies_pt.append(acc_i.item())\n",
        "rounded_accuracies_pt = [round(acc, 4) for acc in accuracies_pt]\n",
        "print(f\"PyTorch Accuracies by Category          : {rounded_accuracies_pt}\")\n",
        "\n",
        "accuracies_tf = []\n",
        "for i in range(num_classes):\n",
        "    pred_binary = tf.cast(predictions_tf[:, i] >= 0.5, tf.float32)\n",
        "    acc = tf.reduce_mean(tf.cast(pred_binary == actuals_tf[:, i], tf.float32))\n",
        "    accuracies_tf.append(acc.numpy())\n",
        "converted_accuracies = [round(float(acc), 4) for acc in accuracies_tf]\n",
        "print(f\"TensorFlow Accuracies by Category       : {converted_accuracies}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY5ruJFxuEvR",
        "outputId": "2235310a-6ac9-4a2f-b1ab-ad058fb20685"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually computed Accuracies by Category: [0.867, 0.871, 0.857]\n",
            "Scikit-learn Accuracies by Category     : [0.867, 0.871, 0.857]\n",
            "PyTorch Accuracies by Category          : [0.867, 0.871, 0.857]\n",
            "TensorFlow Accuracies by Category       : [0.867, 0.871, 0.857]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overall Accuracy"
      ],
      "metadata": {
        "id": "buZnwQFYuHFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected Manual Overall Accuracy\n",
        "def overall_accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes overall accuracy.\n",
        "    \"\"\"\n",
        "    correct = np.sum(np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1))\n",
        "    return correct / len(y_true)"
      ],
      "metadata": {
        "id": "9SbV604LuK4e"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_acc = overall_accuracy(actuals, predictions)\n",
        "print(f\"Manually computed Overall Accuracy: {overall_acc:.4f}\")\n",
        "\n",
        "overall_accuracy_sklearn = accuracy_score(np.argmax(actuals, axis=1),\n",
        "                                          np.argmax(predictions, axis=1))\n",
        "print(f\"Scikit-learn Overall Accuracy     : {overall_accuracy_sklearn:.4f}\")\n",
        "\n",
        "pred_labels = predictions_pt.argmax(dim=1)\n",
        "true_labels = actuals_pt.argmax(dim=1)\n",
        "overall_accuracy_pt = (pred_labels == true_labels).float().mean().item()\n",
        "print(f\"PyTorch Overall Accuracy          : {overall_accuracy_pt:.4f}\")\n",
        "\n",
        "y_true_labels = tf.argmax(actuals_tf, axis=1)\n",
        "y_pred_labels = tf.argmax(predictions_tf, axis=1)\n",
        "accuracy_metric = tf.keras.metrics.Accuracy()\n",
        "accuracy_metric.update_state(y_true_labels, y_pred_labels)\n",
        "overall_accuracy_tf = accuracy_metric.result().numpy()\n",
        "\n",
        "print(f\"TensorFlow Overall Accuracy       : {overall_accuracy_tf:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWiMKvxnuNeb",
        "outputId": "a1c1ca19-0e73-4763-ed32-42fe746c62a6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually computed Overall Accuracy: 0.7940\n",
            "Scikit-learn Overall Accuracy     : 0.7940\n",
            "PyTorch Overall Accuracy          : 0.7940\n",
            "TensorFlow Overall Accuracy       : 0.7940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Log Loss"
      ],
      "metadata": {
        "id": "k6MP3-zyuMDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected Manual Log Loss\n",
        "def log_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes log loss for multi-class classification.\n",
        "    \"\"\"\n",
        "    epsilon = 1e-15  # Small value to avoid log(0)\n",
        "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "    return -np.sum(y_true * np.log(y_pred)) / len(y_true)"
      ],
      "metadata": {
        "id": "-Ex8VDi9nqLp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_loss_value = log_loss(actuals, predictions)\n",
        "print(f\"Manually computed Log Loss: {log_loss_value:.4f}\")\n",
        "\n",
        "log_loss_sklearn = log_loss(actuals, predictions)\n",
        "print(f\"Scikit-learn Log Loss     : {log_loss_sklearn:.4f}\")\n",
        "\n",
        "labels_int = actuals_pt.argmax(dim=1)  # shape (N,)\n",
        "predictions_clamped = predictions_pt.clamp(min=1e-7, max=1.0 - 1e-7)  # avoid log(0)\n",
        "log_loss_pt = F.nll_loss(predictions_clamped.log(), labels_int)\n",
        "print(f\"PyTorch Log Loss          : {log_loss_pt.item():.4f}\")\n",
        "\n",
        "log_loss_metric = tf.keras.losses.CategoricalCrossentropy()\n",
        "log_loss_tf = log_loss_metric(actuals, predictions).numpy()\n",
        "print(f\"TensorFlow Log Loss       : {log_loss_tf:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR8cFXdJqLIA",
        "outputId": "3764e2de-b5c5-4dab-f834-1ccbe7fbe7af"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually computed Log Loss: 0.5372\n",
            "Scikit-learn Log Loss     : 0.5372\n",
            "PyTorch Log Loss          : 0.5372\n",
            "TensorFlow Log Loss       : 0.5372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus Question\n",
        "\n",
        "Replicate Figure 7.1 from the textbook Elements of Statistical Learning in Python. Reference the available R code from the repository: https://github.com/alanjeffares/elements-of-statistical-learning. While it is acceptable to use Gen AI tools to generate the Python code, you must review the generated code for correctness and disclose the Gen AI tool used. Additionally, discuss any issues encountered and highlight errors that were present in the original or generated code. The final code should successfully reproduce the chart to closely resemble the original Figure 7.1."
      ],
      "metadata": {
        "id": "7NqEckYTYLQE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AxXgtAltaj8b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}